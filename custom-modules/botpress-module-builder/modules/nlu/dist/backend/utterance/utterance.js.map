{"version":3,"sources":["utterance/utterance.ts"],"names":["DefaultTokenToStringOptions","lowerCase","realSpaces","trim","Utterance","constructor","tokens","vectors","posTags","languageCode","allSameLength","every","arr","length","Error","i","offset","that","value","push","Object","freeze","index","isBOS","isEOS","isWord","isSpace","slots","filter","x","startTokenIdx","endTokenIdx","entities","tfidf","_globalTfidf","cluster","wordVec","_kmeans","nearest","vector","POS","toString","opts","options","result","toLowerCase","_tokens","sentenceEmbedding","_sentenceEmbedding","totalWeight","dims","Array","fill","token","norm","weight","Math","min","weightedVec","setGlobalTfidf","setKmeans","kmeans","_","defaultsDeep","final","ret","onlyWords","tok","toAdd","name","type","replace","RegExp","SPACE","clone","copyEntities","copySlots","map","POStags","utterance","forEach","entity","tagEntity","startPos","endPos","slot","tagSlot","_validateRange","start","end","lastTok","last","maxEnd","get","range","isEmpty","entityWithPos","first","taggedSlot","buildUtteranceBatch","raw_utterances","language","tools","vocab","parsed","u","tokenUtterances","tokenize_utterances","p","POSUtterances","partOfSpeechUtterances","uniqTokens","uniq","flatten","vectorize_tokens","vectorMap","zipObject","zip","tokUtt","POSUtt","utt","parsedSlots","t","s","source","confidence","cleanPosition","Boolean","uttTok2altTok","pick","isAlter","isClosestTokenValid","originalToken","closestToken","getAlternateUtterance","vocabVectors","chain","strTok","thru","altToks","hasAlternate","some","makeTestUtterance","str","toks","split","SPECIAL_CHARSET","join","vecs","pos"],"mappings":";;;;;;;;;;AACA;;AAGA;;AACA;;AACA;;AACA;;AACA;;AAGA;;;;;;AAmCO,MAAMA,2BAAiD,GAAG;AAAEC,EAAAA,SAAS,EAAE,KAAb;AAAoBC,EAAAA,UAAU,EAAE,IAAhC;AAAsCC,EAAAA,IAAI,EAAE;AAA5C,CAA1D;;;AAEQ,MAAMC,SAAN,CAAgB;AAQ7BC,EAAAA,WAAW,CAACC,MAAD,EAAmBC,OAAnB,EAAwCC,OAAxC,EAAoEC,YAApE,EAAoG;AAAA,SAAhCA,YAAgC,GAAhCA,YAAgC;;AAAA,mCAPjD,EAOiD;;AAAA,sCAN5C,EAM4C;;AAAA,qCAL9D,EAK8D;;AAAA;;AAAA;;AAAA;;AAC7G,UAAMC,aAAa,GAAG,CAACJ,MAAD,EAASC,OAAT,EAAkBC,OAAlB,EAA2BG,KAA3B,CAAiCC,GAAG,IAAIA,GAAG,CAACC,MAAJ,KAAeP,MAAM,CAACO,MAA9D,CAAtB;;AACA,QAAI,CAACH,aAAL,EAAoB;AAClB,YAAMI,KAAK,CAAE,oDAAF,CAAX;AACD;;AAED,UAAMF,GAAG,GAAG,EAAZ;;AACA,SAAK,IAAIG,CAAC,GAAG,CAAR,EAAWC,MAAM,GAAG,CAAzB,EAA4BD,CAAC,GAAGT,MAAM,CAACO,MAAvC,EAA+CE,CAAC,EAAhD,EAAoD;AAClD,YAAME,IAAI,GAAG,IAAb;AACA,YAAMC,KAAK,GAAGZ,MAAM,CAACS,CAAD,CAApB;AACAH,MAAAA,GAAG,CAACO,IAAJ,CACEC,MAAM,CAACC,MAAP,CAAc;AACZC,QAAAA,KAAK,EAAEP,CADK;AAEZQ,QAAAA,KAAK,EAAER,CAAC,KAAK,CAFD;AAGZS,QAAAA,KAAK,EAAET,CAAC,KAAKT,MAAM,CAACO,MAAP,GAAgB,CAHjB;AAIZY,QAAAA,MAAM,EAAE,wBAAOP,KAAP,CAJI;AAKZF,QAAAA,MAAM,EAAEA,MALI;AAMZU,QAAAA,OAAO,EAAE,yBAAQR,KAAR,CANG;;AAOZ,YAAIS,KAAJ,GAA2D;AACzD,iBAAOV,IAAI,CAACU,KAAL,CAAWC,MAAX,CAAkBC,CAAC,IAAIA,CAAC,CAACC,aAAF,IAAmBf,CAAnB,IAAwBc,CAAC,CAACE,WAAF,IAAiBhB,CAAhE,CAAP;AACD,SATW;;AAUZ,YAAIiB,QAAJ,GAAgE;AAC9D,iBAAOf,IAAI,CAACe,QAAL,CAAcJ,MAAd,CAAqBC,CAAC,IAAIA,CAAC,CAACC,aAAF,IAAmBf,CAAnB,IAAwBc,CAAC,CAACE,WAAF,IAAiBhB,CAAnE,CAAP;AACD,SAZW;;AAaZ,YAAIkB,KAAJ,GAAoB;AAClB,iBAAQhB,IAAI,CAACiB,YAAL,IAAqBjB,IAAI,CAACiB,YAAL,CAAkBhB,KAAlB,CAAtB,IAAmD,CAA1D;AACD,SAfW;;AAgBZ,YAAIiB,OAAJ,GAAsB;AACpB,gBAAMC,OAAO,GAAG7B,OAAO,CAACQ,CAAD,CAAvB;AACA,iBAAQE,IAAI,CAACoB,OAAL,IAAgBpB,IAAI,CAACoB,OAAL,CAAaC,OAAb,CAAqB,CAACF,OAAD,CAArB,EAAgC,CAAhC,CAAjB,IAAwD,CAA/D;AACD,SAnBW;;AAoBZlB,QAAAA,KAAK,EAAEA,KApBK;AAqBZqB,QAAAA,MAAM,EAAEhC,OAAO,CAACQ,CAAD,CArBH;AAsBZyB,QAAAA,GAAG,EAAEhC,OAAO,CAACO,CAAD,CAtBA;AAuBZ0B,QAAAA,QAAQ,EAAE,CAACC,IAA0B,GAAG,EAA9B,KAAqC;AAC7C,gBAAMC,OAAO,GAAG,EAAE,GAAG3C,2BAAL;AAAkC,eAAG0C;AAArC,WAAhB;AACA,cAAIE,MAAM,GAAG1B,KAAb;;AACA,cAAIyB,OAAO,CAAC1C,SAAZ,EAAuB;AACrB2C,YAAAA,MAAM,GAAGA,MAAM,CAACC,WAAP,EAAT;AACD;;AACD,cAAIF,OAAO,CAACzC,UAAZ,EAAwB;AACtB0C,YAAAA,MAAM,GAAG,qCAAoBA,MAApB,CAAT;AACD;;AACD,cAAID,OAAO,CAACxC,IAAZ,EAAkB;AAChByC,YAAAA,MAAM,GAAGA,MAAM,CAACzC,IAAP,EAAT;AACD;;AACD,iBAAOyC,MAAP;AACD;AApCW,OAAd,CADF;AAwCA5B,MAAAA,MAAM,IAAIE,KAAK,CAACL,MAAhB;AACD;;AACD,SAAKiC,OAAL,GAAelC,GAAf;AACD;;AAED,MAAIN,MAAJ,GAA4C;AAC1C,WAAO,KAAKwC,OAAZ;AACD;;AAED,MAAIC,iBAAJ,GAAkC;AAChC,QAAI,KAAKC,kBAAT,EAA6B;AAC3B,aAAO,KAAKA,kBAAZ;AACD;;AAED,QAAIC,WAAW,GAAG,CAAlB;AACA,UAAMC,IAAI,GAAG,KAAKJ,OAAL,CAAa,CAAb,EAAgBP,MAAhB,CAAuB1B,MAApC;AACA,QAAIkC,iBAAiB,GAAG,IAAII,KAAJ,CAAUD,IAAV,EAAgBE,IAAhB,CAAqB,CAArB,CAAxB;;AAEA,SAAK,MAAMC,KAAX,IAAoB,KAAK/C,MAAzB,EAAiC;AAC/B,YAAMgD,IAAI,GAAG,uBAAYD,KAAK,CAACd,MAAlB,CAAb;;AACA,UAAIe,IAAI,IAAI,CAAR,IAAa,CAACD,KAAK,CAAC5B,MAAxB,EAAgC;AAC9B;AACA;AACD,OAL8B,CAO/B;;;AACA,YAAM8B,MAAM,GAAGC,IAAI,CAACC,GAAL,CAAS,CAAT,EAAYJ,KAAK,CAACpB,KAAlB,CAAf;AACAgB,MAAAA,WAAW,IAAIM,MAAf;AACA,YAAMG,WAAW,GAAG,wBAAaL,KAAK,CAACd,MAAnB,EAAuCe,IAAI,GAAGC,MAA9C,CAApB;AACAR,MAAAA,iBAAiB,GAAG,qBAAUA,iBAAV,EAA6BW,WAA7B,CAApB;AACD;;AAED,SAAKV,kBAAL,GAA0B,wBAAaD,iBAAb,EAAgCE,WAAhC,CAA1B;AACA,WAAO,KAAKD,kBAAZ;AACD;;AAEDW,EAAAA,cAAc,CAAC1B,KAAD,EAAe;AAC3B,SAAKC,YAAL,GAAoBD,KAApB;AACD;;AAED2B,EAAAA,SAAS,CAACC,MAAD,EAA4C;AACnD,SAAKxB,OAAL,GAAewB,MAAf;AACD,GApG4B,CAsG7B;;;AACApB,EAAAA,QAAQ,CAACE,OAAD,EAA6C;AACnDA,IAAAA,OAAO,GAAGmB,gBAAEC,YAAF,CAAe,EAAf,EAAmBpB,OAAnB,EAA4B;AAAE1C,MAAAA,SAAS,EAAE,KAAb;AAAoB0B,MAAAA,KAAK,EAAE;AAA3B,KAA5B,CAAV;AAEA,QAAIqC,KAAK,GAAG,EAAZ;AACA,QAAIC,GAAG,GAAG,CAAC,GAAG,KAAK3D,MAAT,CAAV;;AACA,QAAIqC,OAAO,CAACuB,SAAZ,EAAuB;AACrBD,MAAAA,GAAG,GAAGA,GAAG,CAACrC,MAAJ,CAAWuC,GAAG,IAAIA,GAAG,CAACxC,KAAJ,CAAUd,MAAV,IAAoBsD,GAAG,CAAC1C,MAA1C,CAAN;AACD;;AAED,SAAK,MAAM0C,GAAX,IAAkBF,GAAlB,EAAuB;AACrB,UAAIG,KAAK,GAAG,EAAZ;;AACA,UAAI,CAACD,GAAG,CAACxC,KAAJ,CAAUd,MAAX,IAAqB,CAACsD,GAAG,CAACnC,QAAJ,CAAanB,MAAvC,EAA+C;AAC7CuD,QAAAA,KAAK,GAAGD,GAAG,CAACjD,KAAZ;AACD,OAJoB,CAMrB;;;AACA,UAAIiD,GAAG,CAACxC,KAAJ,CAAUd,MAAV,IAAoB8B,OAAO,CAAChB,KAAR,KAAkB,WAA1C,EAAuD;AACrDyC,QAAAA,KAAK,GAAGD,GAAG,CAACxC,KAAJ,CAAU,CAAV,EAAa0C,IAArB;AACD,OAFD,MAEO,IAAIF,GAAG,CAACxC,KAAJ,CAAUd,MAAV,IAAoB8B,OAAO,CAAChB,KAAR,KAAkB,YAA1C,EAAwD;AAC7DyC,QAAAA,KAAK,GAAGD,GAAG,CAACjD,KAAZ;AACD,OAFM,MAEA,IAAIiD,GAAG,CAACnC,QAAJ,CAAanB,MAAb,IAAuB8B,OAAO,CAACX,QAAR,KAAqB,WAAhD,EAA6D;AAClEoC,QAAAA,KAAK,GAAGD,GAAG,CAACnC,QAAJ,CAAa,CAAb,EAAgBsC,IAAxB;AACD,OAFM,MAEA,IAAIH,GAAG,CAACnC,QAAJ,CAAanB,MAAb,IAAuB8B,OAAO,CAACX,QAAR,KAAqB,YAAhD,EAA8D;AACnEoC,QAAAA,KAAK,GAAGD,GAAG,CAACnC,QAAJ,CAAa,CAAb,EAAgBd,KAAhB,CAAsBuB,QAAtB,EAAR;AACD,OAFM,MAEA,IAAI0B,GAAG,CAACnC,QAAJ,CAAanB,MAAb,IAAuB8B,OAAO,CAACX,QAAR,KAAqB,cAAhD,EAAgE;AACrEoC,QAAAA,KAAK,GAAGD,GAAG,CAACjD,KAAZ;AACD;;AAED8C,MAAAA,KAAK,IAAII,KAAT;AACD;;AAED,QAAIzB,OAAO,CAAC1C,SAAZ,EAAuB;AACrB+D,MAAAA,KAAK,GAAGA,KAAK,CAACnB,WAAN,EAAR;AACD;;AAED,WAAOmB,KAAK,CAACO,OAAN,CAAc,IAAIC,MAAJ,CAAWC,iBAAX,EAAkB,GAAlB,CAAd,EAAsC,GAAtC,CAAP;AACD;;AAEDC,EAAAA,KAAK,CAACC,YAAD,EAAwBC,SAAxB,EAAuD;AAC1D,UAAMtE,MAAM,GAAG,KAAKA,MAAL,CAAYuE,GAAZ,CAAgBhD,CAAC,IAAIA,CAAC,CAACX,KAAvB,CAAf;AACA,UAAMX,OAAO,GAAG,KAAKD,MAAL,CAAYuE,GAAZ,CAAgBhD,CAAC,IAAcA,CAAC,CAACU,MAAjC,CAAhB;AACA,UAAMuC,OAAO,GAAG,KAAKxE,MAAL,CAAYuE,GAAZ,CAAgBhD,CAAC,IAAIA,CAAC,CAACW,GAAvB,CAAhB;AACA,UAAMuC,SAAS,GAAG,IAAI3E,SAAJ,CAAcE,MAAd,EAAsBC,OAAtB,EAA+BuE,OAA/B,EAAwC,KAAKrE,YAA7C,CAAlB;AACAsE,IAAAA,SAAS,CAACpB,cAAV,CAAyB,EAAE,GAAG,KAAKzB;AAAV,KAAzB;;AAEA,QAAIyC,YAAJ,EAAkB;AAChB,WAAK3C,QAAL,CAAcgD,OAAd,CAAsBC,MAAM,IAAIF,SAAS,CAACG,SAAV,CAAoBD,MAApB,EAA4BA,MAAM,CAACE,QAAnC,EAA6CF,MAAM,CAACG,MAApD,CAAhC;AACD;;AAED,QAAIR,SAAJ,EAAe;AACb,WAAKjD,KAAL,CAAWqD,OAAX,CAAmBK,IAAI,IAAIN,SAAS,CAACO,OAAV,CAAkBD,IAAlB,EAAwBA,IAAI,CAACF,QAA7B,EAAuCE,IAAI,CAACD,MAA5C,CAA3B;AACD;;AAED,WAAOL,SAAP;AACD;;AAEOQ,EAAAA,cAAR,CAAuBC,KAAvB,EAAsCC,GAAtC,EAAmD;AACjD,UAAMC,OAAO,GAAG5B,gBAAE6B,IAAF,CAAO,KAAK7C,OAAZ,CAAhB;;AACA,UAAM8C,MAAM,GAAG9B,gBAAE+B,GAAF,CAAMH,OAAN,EAAe,QAAf,EAAyB,CAAzB,IAA8B5B,gBAAE+B,GAAF,CAAMH,OAAN,EAAe,cAAf,EAA+B,CAA/B,CAA7C;;AAEA,QAAIF,KAAK,GAAG,CAAR,IAAaA,KAAK,GAAGC,GAArB,IAA4BD,KAAK,GAAGI,MAApC,IAA8CH,GAAG,GAAGG,MAAxD,EAAgE;AAC9D,YAAM,IAAI9E,KAAJ,CAAU,eAAV,CAAN;AACD;AACF;;AAEDoE,EAAAA,SAAS,CAACD,MAAD,EAA0BO,KAA1B,EAAyCC,GAAzC,EAAsD;AAC7D,SAAKF,cAAL,CAAoBC,KAApB,EAA2BC,GAA3B;;AACA,UAAMK,KAAK,GAAG,KAAKxF,MAAL,CAAYsB,MAAZ,CAAmBC,CAAC,IAAIA,CAAC,CAACb,MAAF,IAAYwE,KAAZ,IAAqB3D,CAAC,CAACb,MAAF,GAAWa,CAAC,CAACX,KAAF,CAAQL,MAAnB,IAA6B4E,GAA1E,CAAd;;AACA,QAAI3B,gBAAEiC,OAAF,CAAUD,KAAV,CAAJ,EAAsB;AACpB;AACD;;AACD,UAAME,aAAa,GAAG,EACpB,GAAGf,MADiB;AAEpBE,MAAAA,QAAQ,EAAEK,KAFU;AAGpBJ,MAAAA,MAAM,EAAEK,GAHY;AAIpB3D,MAAAA,aAAa,EAAEgC,gBAAEmC,KAAF,CAAQH,KAAR,EAAexE,KAJV;AAKpBS,MAAAA,WAAW,EAAE+B,gBAAE6B,IAAF,CAAOG,KAAP,EAAcxE;AALP,KAAtB;AAQA,SAAKU,QAAL,GAAgB,CAAC,GAAG,KAAKA,QAAT,EAAmBgE,aAAnB,CAAhB;AACD;;AAEDV,EAAAA,OAAO,CAACD,IAAD,EAAsBG,KAAtB,EAAqCC,GAArC,EAAkD;AACvD,SAAKF,cAAL,CAAoBC,KAApB,EAA2BC,GAA3B;;AACA,UAAMK,KAAK,GAAG,KAAKxF,MAAL,CAAYsB,MAAZ,CAAmBC,CAAC,IAAIA,CAAC,CAACb,MAAF,IAAYwE,KAAZ,IAAqB3D,CAAC,CAACb,MAAF,GAAWa,CAAC,CAACX,KAAF,CAAQL,MAAnB,IAA6B4E,GAA1E,CAAd;;AACA,QAAI3B,gBAAEiC,OAAF,CAAUD,KAAV,CAAJ,EAAsB;AACpB;AACD;;AAED,UAAMI,UAAU,GAAG,EACjB,GAAGb,IADc;AAEjBF,MAAAA,QAAQ,EAAEK,KAFO;AAGjBJ,MAAAA,MAAM,EAAEK,GAHS;AAIjB3D,MAAAA,aAAa,EAAEgC,gBAAEmC,KAAF,CAAQH,KAAR,EAAexE,KAJb;AAKjBS,MAAAA,WAAW,EAAE+B,gBAAE6B,IAAF,CAAOG,KAAP,EAAcxE;AALV,KAAnB;AAQA,SAAKK,KAAL,GAAa,CAAC,GAAG,KAAKA,KAAT,EAAgBuE,UAAhB,CAAb;AACD;;AAzM4B;;;;AA4MxB,eAAeC,mBAAf,CACLC,cADK,EAELC,QAFK,EAGLC,KAHK,EAILC,KAJK,EAKiB;AACtB,QAAMC,MAAM,GAAGJ,cAAc,CAACvB,GAAf,CAAmB4B,CAAC,IAAI,qCAAe,uCAAyBA,CAAzB,CAAf,CAAxB,CAAf;AACA,QAAMC,eAAe,GAAG,MAAMJ,KAAK,CAACK,mBAAN,CAC5BH,MAAM,CAAC3B,GAAP,CAAW+B,CAAC,IAAIA,CAAC,CAAC7B,SAAlB,CAD4B,EAE5BsB,QAF4B,EAG5BE,KAH4B,CAA9B;AAKA,QAAMM,aAAa,GAAGP,KAAK,CAACQ,sBAAN,CAA6BJ,eAA7B,EAA8CL,QAA9C,CAAtB;;AACA,QAAMU,UAAU,GAAGjD,gBAAEkD,IAAF,CAAOlD,gBAAEmD,OAAF,CAAUP,eAAV,CAAP,CAAnB;;AACA,QAAMnG,OAAO,GAAG,MAAM+F,KAAK,CAACY,gBAAN,CAAuBH,UAAvB,EAAmCV,QAAnC,CAAtB;;AACA,QAAMc,SAAS,GAAGrD,gBAAEsD,SAAF,CAAYL,UAAZ,EAAwBxG,OAAxB,CAAlB;;AAEA,SAAOuD,gBAAEuD,GAAF,CAAMX,eAAN,EAAuBG,aAAvB,EAAsCL,MAAtC,EACJ3B,GADI,CACA,CAAC,CAACyC,MAAD,EAASC,MAAT,EAAiB;AAAExC,IAAAA,SAAS,EAAEyC,GAAb;AAAkBC,IAAAA;AAAlB,GAAjB,CAAD,KAAuD;AAC1D,QAAIH,MAAM,CAACzG,MAAP,KAAkB,CAAtB,EAAyB;AACvB;AACD;;AACD,UAAMN,OAAO,GAAG+G,MAAM,CAACzC,GAAP,CAAW6C,CAAC,IAAIP,SAAS,CAACO,CAAD,CAAzB,CAAhB;AACA,UAAM3C,SAAS,GAAG,IAAI3E,SAAJ,CAAckH,MAAd,EAAsB/G,OAAtB,EAA+BgH,MAA/B,EAAuClB,QAAvC,CAAlB,CAL0D,CAO1D;AACA;AACA;;AACA,QAAItB,SAAS,CAACtC,QAAV,GAAqB5B,MAArB,KAAgC2G,GAAG,CAAC3G,MAAxC,EAAgD;AAC9C4G,MAAAA,WAAW,CAACzC,OAAZ,CAAoB2C,CAAC,IAAI;AACvB5C,QAAAA,SAAS,CAACO,OAAV,CACE;AAAEjB,UAAAA,IAAI,EAAEsD,CAAC,CAACtD,IAAV;AAAgBuD,UAAAA,MAAM,EAAED,CAAC,CAACzG,KAA1B;AAAiCA,UAAAA,KAAK,EAAEyG,CAAC,CAACzG,KAA1C;AAAiD2G,UAAAA,UAAU,EAAE;AAA7D,SADF,EAEEF,CAAC,CAACG,aAAF,CAAgBtC,KAFlB,EAGEmC,CAAC,CAACG,aAAF,CAAgBrC,GAHlB;AAKD,OAND;AAOD,KAlByD,CAkBxD;;;AAEF,WAAOV,SAAP;AACD,GAtBI,EAuBJnD,MAvBI,CAuBGmG,OAvBH,CAAP;AAwBD;;AASD,SAASC,aAAT,CAAuB3E,KAAvB,EAA8D;AAC5D,SAAO,EACL,GAAGS,gBAAEmE,IAAF,CAAO5E,KAAP,EAAc,CAAC,QAAD,EAAW,KAAX,CAAd,CADE;AAELnC,IAAAA,KAAK,EAAEmC,KAAK,CAACZ,QAAN,EAFF;AAGLyF,IAAAA,OAAO,EAAE;AAHJ,GAAP;AAKD;;AAED,SAASC,mBAAT,CAA6BC,aAA7B,EAA4DC,YAA5D,EAA2F;AACzF,SAAO,wBAAOA,YAAP,KAAwBD,aAAa,CAAClH,KAAd,CAAoBL,MAApB,GAA6B,CAArD,IAA0DwH,YAAY,CAACxH,MAAb,GAAsB,CAAvF;AACD;AAED;;;;;;;AAKO,SAASyH,qBAAT,CAA+BvD,SAA/B,EAAqDwD,YAArD,EAAqG;AAC1G,SAAOzE,gBAAE0E,KAAF,CAAQzD,SAAS,CAACzE,MAAlB,EACJuE,GADI,CACAxB,KAAK,IAAI;AACZ,UAAMoF,MAAM,GAAGpF,KAAK,CAACZ,QAAN,CAAe;AAAExC,MAAAA,SAAS,EAAE;AAAb,KAAf,CAAf;;AACA,QAAI,CAACoD,KAAK,CAAC5B,MAAP,IAAiB8G,YAAY,CAACE,MAAD,CAA7B,IAAyC,CAAC3E,gBAAEiC,OAAF,CAAU1C,KAAK,CAACrB,QAAhB,CAA9C,EAAyE;AACvE,aAAOgG,aAAa,CAAC3E,KAAD,CAApB;AACD;;AAED,UAAMgF,YAAY,GAAG,4BAAgBI,MAAhB,EAAwBpF,KAAK,CAACd,MAA9B,EAAsCgG,YAAtC,EAAoD,KAApD,CAArB;;AACA,QAAIJ,mBAAmB,CAAC9E,KAAD,EAAQgF,YAAR,CAAvB,EAA8C;AAC5C,aAAO;AACLnH,QAAAA,KAAK,EAAEmH,YADF;AAEL9F,QAAAA,MAAM,EAAEgG,YAAY,CAACF,YAAD,CAFf;AAGL7F,QAAAA,GAAG,EAAEa,KAAK,CAACb,GAHN;AAIL0F,QAAAA,OAAO,EAAE;AAJJ,OAAP;AAMD,KAPD,MAOO;AACL,aAAOF,aAAa,CAAC3E,KAAD,CAApB;AACD;AACF,GAlBI,EAmBJqF,IAnBI,CAmBEC,OAAD,IAA+B;AACnC,UAAMC,YAAY,GAAGD,OAAO,CAAC9H,MAAR,KAAmBkE,SAAS,CAACzE,MAAV,CAAiBO,MAApC,IAA8C8H,OAAO,CAACE,IAAR,CAAanB,CAAC,IAAIA,CAAC,CAACQ,OAApB,CAAnE;;AACA,QAAIU,YAAJ,EAAkB;AAChB,aAAO,IAAIxI,SAAJ,CACLuI,OAAO,CAAC9D,GAAR,CAAY6C,CAAC,IAAIA,CAAC,CAACxG,KAAnB,CADK,EAELyH,OAAO,CAAC9D,GAAR,CAAY6C,CAAC,IAAcA,CAAC,CAACnF,MAA7B,CAFK,EAGLoG,OAAO,CAAC9D,GAAR,CAAY6C,CAAC,IAAIA,CAAC,CAAClF,GAAnB,CAHK,EAILuC,SAAS,CAACtE,YAJL,CAAP;AAMD;AACF,GA7BI,EA8BJS,KA9BI,EAAP;AA+BD;AAED;;;;;;AAIO,SAAS4H,iBAAT,CAA2BC,GAA3B,EAAmD;AACxD,QAAMC,IAAI,GAAGD,GAAG,CAACE,KAAJ,CAAU,IAAIzE,MAAJ,CAAY,IAAG0E,uBAAgBC,IAAhB,CAAqB,GAArB,CAA0B,OAAzC,EAAiD,IAAjD,CAAV,CAAb;AACA,QAAMC,IAAI,GAAG,IAAIjG,KAAJ,CAAU6F,IAAI,CAACnI,MAAf,EAAuBuC,IAAvB,CAA4B,CAAC,CAAD,CAA5B,CAAb;AACA,QAAMiG,GAAG,GAAG,IAAIlG,KAAJ,CAAU6F,IAAI,CAACnI,MAAf,EAAuBuC,IAAvB,CAA4B,KAA5B,CAAZ;AACA,SAAO,IAAIhD,SAAJ,CAAc4I,IAAd,EAAoBI,IAApB,EAA0BC,GAA1B,EAA+B,IAA/B,CAAP;AACD","sourceRoot":"/src/modules/nlu/src/backend","sourcesContent":["import * as sdk from 'botpress/sdk'\nimport _ from 'lodash'\n\nimport { POSClass } from '../language/pos-tagger'\nimport { SPECIAL_CHARSET } from '../tools/chars'\nimport { computeNorm, scalarDivide, vectorAdd } from '../tools/math'\nimport { replaceConsecutiveSpaces } from '../tools/strings'\nimport { convertToRealSpaces, isSpace, isWord, SPACE } from '../tools/token-utils'\nimport { getClosestToken } from '../tools/vocab'\nimport { ExtractedEntity, ExtractedSlot, TFIDF, Token2Vec, Tools } from '../typings'\n\nimport { parseUtterance } from './utterance-parser'\n\nexport type UtteranceToStringOptions = {\n  lowerCase?: boolean\n  onlyWords?: boolean\n  slots?: 'keep-value' | 'keep-name' | 'ignore'\n  entities?: 'keep-default' | 'keep-value' | 'keep-name' | 'ignore'\n}\n\nexport type TokenToStringOptions = {\n  lowerCase?: boolean\n  trim?: boolean\n  realSpaces?: boolean\n}\n\nexport type UtteranceRange = { startTokenIdx: number; endTokenIdx: number; startPos: number; endPos: number }\nexport type UtteranceEntity = Readonly<UtteranceRange & ExtractedEntity>\nexport type UtteranceSlot = Readonly<UtteranceRange & ExtractedSlot>\nexport type UtteranceToken = Readonly<{\n  index: number\n  value: string\n  isWord: boolean\n  isSpace: boolean\n  isBOS: boolean\n  isEOS: boolean\n  POS: POSClass\n  vector: ReadonlyArray<number>\n  tfidf: number\n  cluster: number\n  offset: number\n  entities: ReadonlyArray<UtteranceRange & ExtractedEntity>\n  slots: ReadonlyArray<UtteranceRange & ExtractedSlot>\n  toString(options?: TokenToStringOptions): string\n}>\n\nexport const DefaultTokenToStringOptions: TokenToStringOptions = { lowerCase: false, realSpaces: true, trim: false }\n\nexport default class Utterance {\n  public slots: ReadonlyArray<UtteranceRange & UtteranceSlot> = []\n  public entities: ReadonlyArray<UtteranceRange & UtteranceEntity> = []\n  private _tokens: ReadonlyArray<UtteranceToken> = []\n  private _globalTfidf?: TFIDF\n  private _kmeans?: sdk.MLToolkit.KMeans.KmeansResult\n  private _sentenceEmbedding?: number[]\n\n  constructor(tokens: string[], vectors: number[][], posTags: POSClass[], public languageCode: Readonly<string>) {\n    const allSameLength = [tokens, vectors, posTags].every(arr => arr.length === tokens.length)\n    if (!allSameLength) {\n      throw Error(`Tokens, vectors and postTags dimensions must match`)\n    }\n\n    const arr = []\n    for (let i = 0, offset = 0; i < tokens.length; i++) {\n      const that = this\n      const value = tokens[i]\n      arr.push(\n        Object.freeze({\n          index: i,\n          isBOS: i === 0,\n          isEOS: i === tokens.length - 1,\n          isWord: isWord(value),\n          offset: offset,\n          isSpace: isSpace(value),\n          get slots(): ReadonlyArray<UtteranceRange & ExtractedSlot> {\n            return that.slots.filter(x => x.startTokenIdx <= i && x.endTokenIdx >= i)\n          },\n          get entities(): ReadonlyArray<UtteranceRange & ExtractedEntity> {\n            return that.entities.filter(x => x.startTokenIdx <= i && x.endTokenIdx >= i)\n          },\n          get tfidf(): number {\n            return (that._globalTfidf && that._globalTfidf[value]) || 1\n          },\n          get cluster(): number {\n            const wordVec = vectors[i]\n            return (that._kmeans && that._kmeans.nearest([wordVec])[0]) || 1\n          },\n          value: value,\n          vector: vectors[i],\n          POS: posTags[i],\n          toString: (opts: TokenToStringOptions = {}) => {\n            const options = { ...DefaultTokenToStringOptions, ...opts }\n            let result = value\n            if (options.lowerCase) {\n              result = result.toLowerCase()\n            }\n            if (options.realSpaces) {\n              result = convertToRealSpaces(result)\n            }\n            if (options.trim) {\n              result = result.trim()\n            }\n            return result\n          }\n        }) as UtteranceToken\n      )\n      offset += value.length\n    }\n    this._tokens = arr\n  }\n\n  get tokens(): ReadonlyArray<UtteranceToken> {\n    return this._tokens\n  }\n\n  get sentenceEmbedding(): number[] {\n    if (this._sentenceEmbedding) {\n      return this._sentenceEmbedding\n    }\n\n    let totalWeight = 0\n    const dims = this._tokens[0].vector.length\n    let sentenceEmbedding = new Array(dims).fill(0)\n\n    for (const token of this.tokens) {\n      const norm = computeNorm(token.vector as number[])\n      if (norm <= 0 || !token.isWord) {\n        // ignore special char tokens in sentence embeddings\n        continue\n      }\n\n      // hard limit on TFIDF of (we don't want to over scale the features)\n      const weight = Math.min(1, token.tfidf)\n      totalWeight += weight\n      const weightedVec = scalarDivide(token.vector as number[], norm / weight)\n      sentenceEmbedding = vectorAdd(sentenceEmbedding, weightedVec)\n    }\n\n    this._sentenceEmbedding = scalarDivide(sentenceEmbedding, totalWeight)\n    return this._sentenceEmbedding\n  }\n\n  setGlobalTfidf(tfidf: TFIDF) {\n    this._globalTfidf = tfidf\n  }\n\n  setKmeans(kmeans: sdk.MLToolkit.KMeans.KmeansResult) {\n    this._kmeans = kmeans\n  }\n\n  // TODO memoize this for better perf\n  toString(options?: UtteranceToStringOptions): string {\n    options = _.defaultsDeep({}, options, { lowerCase: false, slots: 'keep-value' })\n\n    let final = ''\n    let ret = [...this.tokens]\n    if (options.onlyWords) {\n      ret = ret.filter(tok => tok.slots.length || tok.isWord)\n    }\n\n    for (const tok of ret) {\n      let toAdd = ''\n      if (!tok.slots.length && !tok.entities.length) {\n        toAdd = tok.value\n      }\n\n      // case ignore is handled implicitly\n      if (tok.slots.length && options.slots === 'keep-name') {\n        toAdd = tok.slots[0].name\n      } else if (tok.slots.length && options.slots === 'keep-value') {\n        toAdd = tok.value\n      } else if (tok.entities.length && options.entities === 'keep-name') {\n        toAdd = tok.entities[0].type\n      } else if (tok.entities.length && options.entities === 'keep-value') {\n        toAdd = tok.entities[0].value.toString()\n      } else if (tok.entities.length && options.entities === 'keep-default') {\n        toAdd = tok.value\n      }\n\n      final += toAdd\n    }\n\n    if (options.lowerCase) {\n      final = final.toLowerCase()\n    }\n\n    return final.replace(new RegExp(SPACE, 'g'), ' ')\n  }\n\n  clone(copyEntities: boolean, copySlots: boolean): Utterance {\n    const tokens = this.tokens.map(x => x.value)\n    const vectors = this.tokens.map(x => <number[]>x.vector)\n    const POStags = this.tokens.map(x => x.POS)\n    const utterance = new Utterance(tokens, vectors, POStags, this.languageCode)\n    utterance.setGlobalTfidf({ ...this._globalTfidf })\n\n    if (copyEntities) {\n      this.entities.forEach(entity => utterance.tagEntity(entity, entity.startPos, entity.endPos))\n    }\n\n    if (copySlots) {\n      this.slots.forEach(slot => utterance.tagSlot(slot, slot.startPos, slot.endPos))\n    }\n\n    return utterance\n  }\n\n  private _validateRange(start: number, end: number) {\n    const lastTok = _.last(this._tokens)\n    const maxEnd = _.get(lastTok, 'offset', 0) + _.get(lastTok, 'value.length', 0)\n\n    if (start < 0 || start > end || start > maxEnd || end > maxEnd) {\n      throw new Error('Invalid range')\n    }\n  }\n\n  tagEntity(entity: ExtractedEntity, start: number, end: number) {\n    this._validateRange(start, end)\n    const range = this.tokens.filter(x => x.offset >= start && x.offset + x.value.length <= end)\n    if (_.isEmpty(range)) {\n      return\n    }\n    const entityWithPos = {\n      ...entity,\n      startPos: start,\n      endPos: end,\n      startTokenIdx: _.first(range).index,\n      endTokenIdx: _.last(range).index\n    }\n\n    this.entities = [...this.entities, entityWithPos]\n  }\n\n  tagSlot(slot: ExtractedSlot, start: number, end: number) {\n    this._validateRange(start, end)\n    const range = this.tokens.filter(x => x.offset >= start && x.offset + x.value.length <= end)\n    if (_.isEmpty(range)) {\n      return\n    }\n\n    const taggedSlot = {\n      ...slot,\n      startPos: start,\n      endPos: end,\n      startTokenIdx: _.first(range).index,\n      endTokenIdx: _.last(range).index\n    }\n\n    this.slots = [...this.slots, taggedSlot]\n  }\n}\n\nexport async function buildUtteranceBatch(\n  raw_utterances: string[],\n  language: string,\n  tools: Tools,\n  vocab?: Token2Vec\n): Promise<Utterance[]> {\n  const parsed = raw_utterances.map(u => parseUtterance(replaceConsecutiveSpaces(u)))\n  const tokenUtterances = await tools.tokenize_utterances(\n    parsed.map(p => p.utterance),\n    language,\n    vocab\n  )\n  const POSUtterances = tools.partOfSpeechUtterances(tokenUtterances, language) as POSClass[][]\n  const uniqTokens = _.uniq(_.flatten(tokenUtterances))\n  const vectors = await tools.vectorize_tokens(uniqTokens, language)\n  const vectorMap = _.zipObject(uniqTokens, vectors)\n\n  return _.zip(tokenUtterances, POSUtterances, parsed)\n    .map(([tokUtt, POSUtt, { utterance: utt, parsedSlots }]) => {\n      if (tokUtt.length === 0) {\n        return\n      }\n      const vectors = tokUtt.map(t => vectorMap[t])\n      const utterance = new Utterance(tokUtt, vectors, POSUtt, language)\n\n      // TODO: temporary work-around\n      // covers a corner case where tokenization returns tokens that are not identical to `parsed` utterance\n      // the corner case is when there's a trailing space inside a slot at the end of the utterance, e.g. `my name is [Sylvain ](any)`\n      if (utterance.toString().length === utt.length) {\n        parsedSlots.forEach(s => {\n          utterance.tagSlot(\n            { name: s.name, source: s.value, value: s.value, confidence: 1 },\n            s.cleanPosition.start,\n            s.cleanPosition.end\n          )\n        })\n      } // else we skip the slot\n\n      return utterance\n    })\n    .filter(Boolean)\n}\n\ninterface AlternateToken {\n  value: string\n  vector: number[] | ReadonlyArray<number>\n  POS: POSClass\n  isAlter?: boolean\n}\n\nfunction uttTok2altTok(token: UtteranceToken): AlternateToken {\n  return {\n    ..._.pick(token, ['vector', 'POS']),\n    value: token.toString(),\n    isAlter: false\n  }\n}\n\nfunction isClosestTokenValid(originalToken: UtteranceToken, closestToken: string): boolean {\n  return isWord(closestToken) && originalToken.value.length > 3 && closestToken.length > 3\n}\n\n/**\n * @description Returns slightly different version of the given utterance, replacing OOV tokens with their closest IV syntaxical neighbour\n * @param utterance the original utterance\n * @param vocabVectors Bot wide vocabulary\n */\nexport function getAlternateUtterance(utterance: Utterance, vocabVectors: Token2Vec): Utterance | undefined {\n  return _.chain(utterance.tokens)\n    .map(token => {\n      const strTok = token.toString({ lowerCase: true })\n      if (!token.isWord || vocabVectors[strTok] || !_.isEmpty(token.entities)) {\n        return uttTok2altTok(token)\n      }\n\n      const closestToken = getClosestToken(strTok, token.vector, vocabVectors, false)\n      if (isClosestTokenValid(token, closestToken)) {\n        return {\n          value: closestToken,\n          vector: vocabVectors[closestToken],\n          POS: token.POS,\n          isAlter: true\n        } as AlternateToken\n      } else {\n        return uttTok2altTok(token)\n      }\n    })\n    .thru((altToks: AlternateToken[]) => {\n      const hasAlternate = altToks.length === utterance.tokens.length && altToks.some(t => t.isAlter)\n      if (hasAlternate) {\n        return new Utterance(\n          altToks.map(t => t.value),\n          altToks.map(t => <number[]>t.vector),\n          altToks.map(t => t.POS),\n          utterance.languageCode\n        )\n      }\n    })\n    .value()\n}\n\n/**\n * @description Utility function that returns an utterance using a space tokenizer\n * @param str sentence as a textual value\n */\nexport function makeTestUtterance(str: string): Utterance {\n  const toks = str.split(new RegExp(`(${SPECIAL_CHARSET.join('|')}|\\\\s)`, 'gi'))\n  const vecs = new Array(toks.length).fill([0])\n  const pos = new Array(toks.length).fill('N/A')\n  return new Utterance(toks, vecs, pos, 'en')\n}\n"]}